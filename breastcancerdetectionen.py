# -*- coding: utf-8 -*-
"""BreastCancerDetectionEN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oxsEkUuiHMf0AUARlsk8HW-ZZw14JVGh
"""

train_path = '/content/drive/MyDrive/DATASETS/BreastCancer1/train'
test_path = '/content/drive/MyDrive/DATASETS/BreastCancer1/test'

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.layers import *
from keras.models import *
from keras.preprocessing import image
from tensorflow.keras import models,layers
import os
import glob
import cv2
from keras.applications.vgg16 import VGG16

print(os.listdir("/content/drive/MyDrive/DATASETS/BreastCancer1"))
print(glob.glob('/content/drive/MyDrive/DATASETS/BreastCancer1/train/*'))
print(glob.glob('/content/drive/MyDrive/DATASETS/BreastCancer1/test/*'))
classes = ["NoCancer","Cancer"]

train_images=[]
train_labels=[]
for directory_path in glob.glob('/content/drive/MyDrive/DATASETS/BreastCancer1/train/*'):
  label=directory_path.split("//")[-1]
  print(label)
  for img_path in glob.glob(os.path.join(directory_path,"*.png")):
    print(img_path)
    img=cv2.imread(img_path,cv2.IMREAD_COLOR)
    img=cv2.resize(img,(224,224))
    img=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)
    train_images.append(img)
    train_labels.append(label)

test_images=[]
test_labels=[]
for directory_path in glob.glob('/content/drive/MyDrive/DATASETS/BreastCancer1/test/*'):
  label=directory_path.split("//")[-1]
  print(label)
  for img_path in glob.glob(os.path.join(directory_path,"*.png")):
    print(img_path)
    img=cv2.imread(img_path,cv2.IMREAD_COLOR)
    img=cv2.resize(img,(224,224))
    img=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)
    test_images.append(img)
    test_labels.append(label)

train_images=np.asarray(train_images)
train_labels=np.asarray(train_labels)
test_images=np.asarray(test_images)
test_labels=np.asarray(test_labels)
train_images.shape

from sklearn import preprocessing
le=preprocessing.LabelEncoder()
le.fit(test_labels)
test_labels_encoded=le.transform(test_labels)
le.fit(train_labels)
train_labels_encoded=le.transform(train_labels)

test_labels_encoded

x_train,y_train,x_test,y_test=train_images,train_labels_encoded,test_images,test_labels_encoded

x_test.shape

plt.imshow(x_test[2])
test_labels[2]

def plot_sample(X, y, index):
    plt.figure(figsize = (15,2))
    plt.imshow(X[index])
    plt.xlabel(classes[y[index]])

plot_sample(x_train, y_train, 100)

#x_train_flatten=x_train.reshape(len(x_train),224*224,3)
#print("After Flattening the shape of x_train is : ",x_train_flatten.shape)
#x_test_flatten=x_test.reshape(len(x_test),224*224,3)
#print("After Flattening the shape of x_test is : ",x_test_flatten.shape)

X_train = x_train / 255.0
X_test = x_test / 255.0

X_train[0]

cnn = models.Sequential([
    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(128, activation='relu'),
    layers.Dense(256, activation='relu'),
    layers.Dense(2, activation='sigmoid')
])

cnn.summary()

X_train[0].shape

cnn.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
cnn.fit(X_train, y_train, epochs=20)

cnn.evaluate(X_test,y_test)

y_pred = cnn.predict(X_test)
y_pred

y_classes = [np.argmax(element) for element in y_pred]
y_classes[:5]

plot_sample(X_test, y_test,2)

for i in range(len(y_pred)):
  plot_sample(x_test,y_test,i)

"""***Implementation of VGG16***"""

from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img

vgg16=VGG16(weights='imagenet',include_top=False,input_shape=(224,224,3))
vgg19=VGG19(weights='imagenet',include_top=False,input_shape=(224,224,3))

for layer in vgg16.layers:
  layer.trainable=False
for layer in vgg19.layers:
  layer.trainable=False

folders=glob.glob('/content/drive/MyDrive/DATASETS/BreastCancer1/train/*')
x=Flatten()(vgg16.output)
x1=Flatten()(vgg19.output)
prediction=Dense(len(folders),activation='softmax')(x)
prediction1=Dense(len(folders),activation='softmax')(x1)

model=Model(inputs=vgg16.input,outputs=prediction)
model.summary()

model1=Model(inputs=vgg19.input,outputs=prediction1)
model.summary()

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model1.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

train_datagen=ImageDataGenerator(rescale=1./255,
                                 shear_range=0.2,
                                 zoom_range=0.2,
                                 horizontal_flip=True)
test_datagen=ImageDataGenerator(rescale=1./255)

training_set=train_datagen.flow_from_directory('/content/drive/MyDrive/DATASETS/BreastCancer1/train',target_size=(224,224),batch_size=32,class_mode='categorical')
testing_set=train_datagen.flow_from_directory('/content/drive/MyDrive/DATASETS/BreastCancer1/test',target_size=(224,224),batch_size=32,class_mode='categorical')

r=model.fit_generator(
    training_set,
    validation_data=testing_set,
    epochs=20,
    steps_per_epoch=len(training_set),
    validation_steps=len(testing_set)
)

r1=model1.fit_generator(
    training_set,
    validation_data=testing_set,
    epochs=20,
    steps_per_epoch=len(training_set),
    validation_steps=len(testing_set)
)

#VGG16
plt.plot(r.history['loss'],label='train_loss')
plt.plot(r.history['val_loss'],label='val loss')
plt.legend()
plt.show()
plt.savefig('LossVal_loss')

plt.plot(r.history['accuracy'],label='train_acc')
plt.plot(r.history['val_accuracy'],label='val acc')
plt.legend()
plt.show()
plt.savefig('AccVal_loss')

#VGG19
plt.plot(r1.history['loss'],label='train_loss')
plt.plot(r1.history['val_loss'],label='val loss')
plt.legend()
plt.show()
plt.savefig('LossVal_loss')

plt.plot(r1.history['accuracy'],label='train_acc')
plt.plot(r1.history['val_accuracy'],label='val acc')
plt.legend()
plt.show()
plt.savefig('AccVal_loss')

"""***SVC RBF***"""

train_images1=[]
train_labels1=[]
for directory_path in glob.glob('/content/drive/MyDrive/DATASETS/BreastCancer1/train/*'):
  label=directory_path.split("//")[-1]
  print(label)
  for img_path in glob.glob(os.path.join(directory_path,"*.png")):
    print(img_path)
    img=cv2.imread(img_path,cv2.IMREAD_COLOR)
    img=cv2.resize(img,(224,224))
    img=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)
    train_images1.append(img)
    train_labels1.append(label)

val_images=[]
val_labels=[]
for directory_path in glob.glob('/content/drive/MyDrive/DATASETS/BreastCancer1/test/*'):
  label=directory_path.split("//")[-1]
  print(label)
  for img_path in glob.glob(os.path.join(directory_path,"*.png")):
    print(img_path)
    img=cv2.imread(img_path,cv2.IMREAD_COLOR)
    img=cv2.resize(img,(224,224))
    img=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)
    val_images.append(img)
    val_labels.append(label)

val_images=np.asarray(val_images)
val_labels=np.asarray(val_labels)
train_images1=np.asarray(train_images1)
train_labels1=np.asarray(train_labels1)

from sklearn import preprocessing
le=preprocessing.LabelEncoder()
le.fit(val_labels)
val_labels_encoded=le.transform(val_labels)
le.fit(train_labels1)
train_labels_encoded=le.transform(train_labels1)
print(train_labels_encoded)

x_train,y_train,x_val,y_val=train_images,train_labels_encoded,val_images,val_labels_encoded

x_train,x_val=x_train/255.0,x_val/255.0

#Feature Extraction
feature_extractor=vgg16.predict(x_train)
features=feature_extractor.reshape(feature_extractor.shape[0],-1)
x_training=features

from sklearn import svm
model=svm.SVC(kernel='rbf',gamma=0.01)
model.fit(x_training,train_labels_encoded)

x_val_feature=vgg16.predict(x_val)
x_val_features=x_val_feature.reshape(x_val_feature.shape[0],-1)
prediction=model.predict(x_val_features)
prediction

from sklearn import metrics
print("Accuracy = ", metrics.accuracy_score(prediction,val_labels_encoded))

import pandas as pd 

lst=['Models','CNN','VGG16','VGG19','RBF']
lst1=['Accuracy Highest','90','95','90','90']

dframe = pd.DataFrame(lst1,lst)  
dframe.head()

#EfficientNet Implementation

from tensorflow.keras import layers
from tensorflow.keras.applications import EfficientNetB0

NUM_CLASSES = 2
IMG_SIZE = 224
size = (IMG_SIZE, IMG_SIZE)

inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))

#Using model without transfer learning

outputs = EfficientNetB0(include_top = True, weights = None, classes=NUM_CLASSES)(inputs)

model = tf.keras.Model(inputs, outputs)
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])
model.summary()

x_train.shape

model.fit(x_train, y_train, epochs=20)

import matplotlib.pyplot as plt

plt.plot(model.history.history["accuracy"])
plt.title("model accuracy")
plt.ylabel("accuracy")
plt.xlabel("epoch")
plt.legend(["train","validation"], loc="upper left")
plt.show()

pred = model.evaluate(x_test, y_test)
pred

print("loss "+str(pred[0]))
print("Accuracy on Test Dataset : "+ str(pred[1]))

#Instead of learning, the alogrithm seems to be memorizing instead of learning and thus the model is overfit to some extent

y_pred = model.predict(X_test)

for i in range(len(y_pred)):
  plot_sample(x_test,y_test,i)

import pandas as pd 

lst=['Models','CNN','VGG16','VGG19','RBF','EN']
lst1=['Highest Train Accuracy','90','95','90','90','85']

dframe = pd.DataFrame(lst1,lst)  
dframe

